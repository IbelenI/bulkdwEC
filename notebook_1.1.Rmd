---
title: "BulkdwEC"
output: html_notebook
---

#### Setup
```{r setup, echo=F}
#Those are local folders for my convenience, please ignore.
loc  <- "G://00_PhD_II//Rfolder//bulkdwEC//" #getwd()
loca <- "G://00_PhD_II//Rfolder//bulkdwEC//auxi//"
locd <- "G://00_PhD_II//Rfolder//bulkdwEC//data//"
loct <- "G://00_PhD_II//Rfolder//bulkdwEC//temp//"


#Libraries

#For the first time I am using "tidyverse" for data manipulation which includes some packages I normally use and some that are imposing me a different approach: "ggplot2", "dplyr", "tidyr", "readr", "purrr", stringr, "forcats". More info: https://www.tidyverse.org/packages/

  # install.packages("tidyverse")
  library (tidyverse, quietly=T, warn.conflicts=F, logical.return=F)

# From my old-fashion way of working, should bot be necessary, we'll see...
  # library ("reshape2")
  # library ("glue") #This one conflicts with collapse from "dplyr"


# For piping %>%; but I already have tidyverse...
  # library(magrittr, quietly=T, warn.conflicts=F, logical.return=F)

# Dates: 
  library (lubridate, quietly=T, warn.conflicts=F, logical.return=F)
  
# Retrieve time series from Eurostat's Bulk Download Facility
  # install.packages("eurostat")
  library (eurostat, quietly=T, warn.conflicts=F, logical.return=F)



# Table formatting.
    library (xtable, quietly=T, warn.conflicts=F, logical.return=F)
    library (knitr, quietly=T, warn.conflicts=F, logical.return=F)



#For Time Series anaysis and ggplot2 extensions for ts objects
    install.packages(
      c("ggfortify", "changepoint",
        "strucchange", "ggpmisc")
    )
    library (ggfortify, quietly=T, warn.conflicts=F, logical.return=F)
    library (changepoint, quietly=T, warn.conflicts=F, logical.return=F)
    #package "changepoint" was built under R version 4.0.2
    #The following objects are masked from package:base: as.Date, as.Date.numeric
    #NOTE: Predefined penalty values changed in version 2.2.  Previous penalty values with a postfix 1 i.e. SIC1 are now without i.e. SIC and previous penalties without a postfix i.e. SIC are now with a postfix 0 i.e. SIC0. See NEWS and help files for further details.
    library (strucchange, quietly=T, warn.conflicts=F, logical.return=F)
    #package "strucchange" was built under R version
    #Loading required package: "sandwich" built under R version 4.0.2
    #The following object is masked from package:stringr: boundary
    library (ggpmisc, quietly=T, warn.conflicts=F, logical.return=F) #Identify change point and break points.
    #package "ggpmisc" was built under R version 4.0.2


    #Detect peaks and valleys:
    library(ggpmisc, quietly=T, warn.conflicts=F, logical.return=F)

    
#When loading tidyverse:
    # package �tidyverse� was built under R version 4.0.2Registered S3 method overwritten by 'dplyr':
    #   method           from
    #   print.rowwise_df     
    # Registered S3 methods overwritten by 'dbplyr':
    #   method         from
    #   print.tbl_lazy     
    #   print.tbl_sql      
    # -- Attaching packages --------------------------------------- tidyverse 1.3.0 --
    # v ggplot2 3.3.0     v purrr   0.3.4
    # v tibble  3.0.1     v dplyr   0.8.5
    # v tidyr   1.1.0     v stringr 1.4.0
    # v readr   1.3.1     v forcats 0.5.0
    # -- Conflicts ------------------------------------------ tidyverse_conflicts() --
    # x lubridate::as.difftime() masks base::as.difftime()
    # x lubridate::date()        masks base::date()
    # x dplyr::filter()          masks stats::filter()
    # x lubridate::intersect()   masks base::intersect()
    # x dplyr::lag()             masks stats::lag()
    # x lubridate::setdiff()     masks base::setdiff()
    # x lubridate::union()       masks base::union()
```

#### <b>Introduction</b>

The Eurostat has a "bulk download facility" to download data from their repositories. From that service is possible to automate the download of data sets. Updates are done twice a day, at 11:00 and 23:00, and the data is available in two formats: tsv (tab separated values) and SDMX (<a href = "https://sdmx.org/?page_id=2555">link</a>).

Information is available in this <a href = "https://ec.europa.eu/eurostat/data/bulkdownload">link</a>.

#### <b>Automatization Download from Eurostat's Bulk Download Facility</b>

Automate for "bulk download" or query specific data is available through REST request (<a href="https://www.w3.org/TR/ws-arch/#relwwwrest">link</a>). They are available either for:

- SDMX Web Services
SDMX, which stands for Statistical Data and Metadata eXchange, is an ISO standard designed to describe statistical data and metadata, normalize their exchange, and improve their efficient sharing across statistical and similar organizations.<br>
Instructions and ussage are available <a href="https://ec.europa.eu/eurostat/web/sdmx-web-services/about-this-service">here</a>.

- JSON Web Services
- UNICODE Web Services<br>
Instructions and usage information for both JSON and UNICODE web services are available <a href = "https://ec.europa.eu/eurostat/web/json-and-unicode-web-services/about-this-service">here</a>.

##### <u>Steps to build a Query</u>

Under the SDMX Web Services, the steps to build a query (please check complete guide with examples <a href = "https://ec.europa.eu/eurostat/web/sdmx-web-services/a-few-useful-points">here</a>).

1- Identify your data flow name.

  - By checking the navigation tree on Eurostat portal homepage.
  
  - By retrieving the list of data flows through our web services and finding the required data flow <a href="http://ec.europa.eu/eurostat/SDMX/diss-web/rest/dataflow/ESTAT/all/latest">here</a>.
  
  - By already knowing a Eurostat data set code, which is the identifier for data flows as well.
  
2- Check the dimensions and their elements.

  - By retrieving the Data Structure Definition (DSD), 
  
  - By checking the Data Explorer for the relevant data, 


    Examples:<br>
    E.g. the REST request for the DSD about nama_10_gdp is <br>  http://ec.europa.eu/eurostat/SDMX/diss-web/rest/datastructure/ESTAT/DSD_nama_10_gdp
  
    E.g. for nama_10_gdp would be: <br>  http://ec.europa.eu/eurostat/product?mode=view&code=nama_10_gdp&language=en

3- Create a key by adding filters for each dimension (except [TIME]).

Check the <i>DataStructure/DataStructureComponents/DimensionList (SDMX2.1)</i> element and take note of the order of the dimensions. Keep in mind that the order of the dimensions is crucial. You need to keep the order as it is stated in the <i>DimensionList</i> in the DSD.

    In the case of nama_10_gdp, the order of dimensions is:

    FREQ (frequency),
    UNIT (unit),
    NA_ITEM (indicator name),
    GEO (geographical dimension).

    For each of those dimensions, we can filter the elements based on the following rules:

      - Key = [FREQ].[UNIT].[NA_ITEM].[GEO]
    
      - "+" can be used as an OR for each of the dimensions (example: [GEO] = EU28+DE+FR+IT : retrieve data only for EU28, Germany, France and Italy)
    
      - "." is used as a separator for the dimensions
    
      - If you want to wildcard (choose all elements) a dimension, just leave an empty space.If the first dimension is wildcarded, just put the separator ".", and you can do the same with the last dimension. For instance, a key of "…" would stand for retrieval of the full dataset: [FREQ].[UNIT].[NA_ITEM].[GEO]

      - The Frequency ([FREQ], mostly first dimension) should only be given, if the dataset contains a mix of several periods (eg. annual and monthly data).


6- Now check the Code list for each dimension by

  - Looking at the DSD <i>Structure/Codelists/Codelist (id="CL_[DimensionName]") (SDMX2.1)</i>. All Codes can be used as elements.

  - Checking the dimension values in Data Explorer.

7- Add [TIME] filtering, if relevant.

    You can do this by adding parameters at the end of the link after a "?" sign, using "startPeriod" and / or "endPeriod".
    
    E.g. in case you would like to filter data starting from 2006 until 2009 included the link would finish with "?startPeriod=2006&endPeriod=2009"

8- Call

    http://ec.europa.eu/eurostat/SDMX/diss-web/rest/data/nama_10_gdp/key 
    
    where you replace key with your creation from above ([FREQ].[UNIT].[NA_ITEM].[GEO]) plus any [TIME] filtering.

##### <u>Working with xml in R</u>

Using the above method oblies to handle information in xml file format. 
```{r xml_eg1}
#No conseguido #####

#Packages:
  install.packages("XML") #this one 2020-07-05
  library (XML)
  #package XML was built under R version 4.0.2
  # library (xml2) #this one 2020-04-23
  library(methods)

con <- "C:\\Users\\belen\\AppData\\Local\\Temp\\DSD_nama_10_gdp_latest_ESTAT_references=none_detail=full.xml"

tree <- xmlTreeParse ( file = con , useInternalNodes = T )
result <- xmlParse(file=con)
# print ( result )
rootnode <- xmlRoot(tree)
rootsize <- xmlSize(rootnode)

# xpathApply(rootnode, "CL_NA_ITEM", xmlValue)

xmldataframe <- xmlToDataFrame(con, stringsAsFactors=FALSE)
```



##### <u>Querying EDP-related data</u>

First I would like a list of all available data.

There is a table of content (TOC) in English where I can get a list of all available data flows <a href = "https://ec.europa.eu/eurostat/estat-navtree-portlet-prod/BulkDownloadListing?sort=1&file=table_of_contents_en.txt">here: table_of_contents_en.txt</a>.

The following code will retrieve the file into a data frame:
```{r data_origin_list}
      #Create a connection:
      con <- "https://ec.europa.eu/eurostat/estat-navtree-portlet-prod/BulkDownloadListing?sort=1&file=table_of_contents_en.txt"

      #List all data flows: data frame of the TOC in English.
      tbcont <- read.table (con, header = T, sep = "\t")
      tbcont$title <- str_trim (tbcont$title) #trim title string
```

There are `r dim (tbcont[which (tbcont$type=="table"),])[1]` tables. The table of contet includes not only tables but also information on folders and data sets. It follows the structure of the <a href="https://ec.europa.eu/eurostat/data/database">Database navigation tree</a>.

Data sets are available in the "data" directory in the bulk download facility <a href="https://ec.europa.eu/eurostat/estat-navtree-portlet-prod/BulkDownloadListing?sort=1&dir=data">here</a>.

    File name differ according if it is SDMX or TSV.
      SDMX:   aact_ali01.sdmx.zip
      TSV:    aact_ali01.tsv.gz

Each file REST request is made with the pattern:

    [con][%2F][data flow code][file extension]

If I want to download all of them I can easily create a vector with all REST requests to be used in a function.

```{r data_origin_all}

    con <- "https://ec.europa.eu/eurostat/estat-navtree-portlet-prod/BulkDownloadListing?sort=1&dir=data"

    alltsvcon <- paste0(con, "%2F", tbcont$code[which (tbcont$type=="table")],".tsv.gz")
    allsdmcon <- paste0(con, "%2F", tbcont$code[which (tbcont$type=="table")],".sdmx.zip")
```

Although, there is already a package names <a href = "https://ropengov.github.io/eurostat"><i>eurostat</i></a> where there are some usefull functions we can implement in the code.

##### <u>Reading "tipsgo10" from Eurostat</u>

This is how we can obtain a list of tables with the time series related to the Excessive Dept Procedure (EDP):
```{r data_origin_eg1}
theme_set(theme_minimal())#Look what is that...

#Remember that the table of content include different type of elements: "comext", "dataset", "folders" and "table". You should make sure that you are searching for the right element.

    #Searching among table.
    ftab <- tbcont %>%
      filter (type=="table")
    
    #Table with code and description of the identified     tables:
    kable ( 
      ftab [grep ("EDP", ftab$title),c("code", "title")]
      )
```

Once the code is identified we can read the data using <i>get_eurostat</i> function from eurostat package.
```{r data_origin_eg2}
edp_month <- get_eurostat ("tipsgo10", cache=F)

      #DSD: Data Strucutre Definition
      cond <- "http://ec.europa.eu/eurostat/SDMX/diss-web/rest/datastructure/ESTAT/DSD_tipsgo10"
      f <- read_file (con)

      tree <- xmlTreeParse ( file = f , useInternalNodes = T )
result <- xmlParse(file=f)
# print ( result )
rootnode <- xmlRoot(tree)

# xpathApply(rootnode, "CL_NA_ITEM", xmlValue)

xmldataframe <- xmlToDataFrame(f, stringsAsFactors=FALSE)
      
      
      
      
#We can filter the data afterwards. We could query the data using JSON Web Services from Eurostat. Although at the moment of this exercise have some limitations.
emonth <- edp_month%>%
            filter (year(time)>1999)%>%
            filter (geo%in%c("ES","BE"))%>%
            filter (unit=="PC_GDP") %>%
            # mutate (month = factor(month (time))) %>%
            mutate (year = factor(year (time))) %>%
            select (na_item, unit, geo, values, year)

#Remember to clean the cache of Eurostat folder
  # C:\Users\Public\Documents\Wondershare\CreatorTemp\RtmpMvim0M/eurostat/tipsgo10_date_code_FF.rds

  # We can also set cache=F in the "get_eurostat" function if we are sure that the size of the table is not going to require the use of the cache.

  # clean_eurostat_cache(cache_dir = NULL)
```

##### <u>Basic ggplot of time series</u>
Some ideas taken from <a href="http://www.sthda.com/english/articles/32-r-graphics-essentials/128-plot-time-series-data-using-ggplot/"><i>R Graphics Essentials for Great Data Visualization</a>: +200 Practical Examples You Want to Know for Data Science</i>.  

```{r plot_eg1}
# library(ggplot2)
theme_set(theme_minimal())
# Demo data set
# head(economics)

# Basic line plot
p   <- ggplot(
    data = economics, aes(x = date, y = pop)
    )+
    geom_line(color = "#00AFBB", size = 2)

# Plot a subset of the data
ss  <- subset(economics, date > as.Date("2006-1-1"))
p   <- ggplot(
    data = ss, aes(x = date, y = pop)
    ) +
    geom_line(color = "#FC4E07", size = 2)

#Control line size by the value of a continuous variable:
p   <- ggplot(
    data = economics, aes(x = date, y = pop)) +
    geom_line(aes(size = unemploy/pop),
              color = "#FC4E07")

# library(tidyr)
# library(dplyr)
df <- economics %>%
  select(date, psavert, uempmed) %>%
  gather(key = "variable", value = "value", -date)
# head(df, 3)

# Multiple line plot
p    <- ggplot(
        df, aes(x = date, y = value)) + 
        geom_line(aes(color = variable), size = 1) +
        scale_color_manual(values = c("#00AFBB",
                                      "#E7B800")) +
        theme_minimal()

# Area plot
p    <- ggplot(
        df, aes(x = date, y = value)) + 
        geom_area(aes(color = variable, 
                      fill = variable),
                  alpha = 0.5, 
                  position = position_dodge(0.8)) +
        scale_color_manual(values = c("#00AFBB",
                                      "#E7B800")) +
        scale_fill_manual(values = c("#00AFBB",
                                     "#E7B800"))


# Base plot with date axis
p    <- ggplot(
        data = economics, aes(x = date, y = psavert)) +         geom_line(color = "#00AFBB", size = 1)

# Set axis limits c(min, max)
min <- as.Date("2002-1-1")
max <- NA
p1    <- p + scale_x_date(limits = c(min, max))

# Format : month/year
p2    <- p + scale_x_date(date_labels = "%b/%Y")

# Add trend smoothed line
p    <- p + stat_smooth(
              color = "#FC4E07",
              fill = "#FC4E07",
              method = "loess")
```

##### <u>ggplot2 extensions for ts objects</u>
```{r plot_eg2}
#First, install required R packages:
    # install.packages(c("ggfortify", "changepoint",
    # "strucchange", "ggpmisc"))
    # library(ggfortify)
    # library(magrittr) # for piping %>%

# Plot ts objects
autoplot(AirPassengers)
# Identify change points in mean and variance
AirPassengers %>%
  changepoint:: cpt.meanvar() %>%  
  autoplot()

  # "cpt.meanvar()" Identify change points. You may want to chek this out: "Identifying Changes in Mean and Variance"
  # https://www.rdocumentation.org/packages/changepoint/versions/2.2.2/topics/cpt.meanvar
  

# Detect jump in a data
strucchange::breakpoints(Nile ~ 1) %>%
  autoplot()

# Computation of breakpoints in regression relationships. Given a number of breaks the function computes the optimal breakpoints. Chek it out here: https://www.rdocumentation.org/packages/strucchange/versions/1.5-2/topics/breakpoints

#Detect peaks and valleys:
# library(ggpmisc)
ggplot(lynx, as.numeric = FALSE) + geom_line() + 
  stat_peaks(colour = "red") +
  stat_peaks(geom = "text", colour = "red", 
             vjust = -0.5, x.label.fmt = "%Y") +
  stat_valleys(colour = "blue") +
  stat_valleys(geom = "text", colour = "blue", angle = 45,
               vjust = 1.5, hjust = 1,  x.label.fmt = "%Y")+
  ylim(-500, 7300)

```




```{r plot_origin_eg1}
theme_set(theme_minimal())

# Basic line plot
p1 <- ggplot (data = emonth, aes(x = year, y = values,
                                  group=geo))+
       geom_line(color = "#00AFBB", size = 2)

# Plot a subset of the data
ss  <- subset(emonth, geo == "ES")
p2 <- ggplot(data = ss, aes(x = year, y = values,
                             group=geo)) + 
       geom_line(color = "#FC4E07", size = 2)

# Area plot
p3 <- ggplot(emonth, aes(x = year, y = values,
                          group=geo)) + 
       geom_area(aes(color = geo, fill = geo),
                 alpha = 0.5,
                 position = position_dodge(0.8)) +
       scale_color_manual ( values = c("#00AFBB", "#E7B800")) +
       scale_fill_manual ( values = c("#00AFBB", "#E7B800"))


#Add trend smooth line
p4 <- p1 + stat_smooth(
            color = "#FC4E07", fill = "#FC4E07",
            method = "loess")





# Demo dataset
head(economics)
# Base plot with date axis
p <- ggplot(data = economics, aes(x = date, y = psavert)) + 
     geom_line(color = "#00AFBB", size = 1)
p
# Set axis limits c(min, max)
min <- as.Date("2002-1-1")
max <- NA
p + scale_x_date(limits = c(min, max))
# Format : month/year
p + scale_x_date(date_labels = "%b/%Y")

#Add trend smooth line
p + stat_smooth(
  color = "#FC4E07", fill = "#FC4E07",
  method = "loess"
  )





plot (
  names(table(emonth$year)),
  emonth$values[which (emonth$geo=="ES")],
  las = 2, 
  ylab=names(table(emonth$na_item)),
  xlab="year"
  )

lines (emonth$values[which (emonth$geo=="ES")])


```



Notes:

    I have also localized a package to open SDMX files which would allow download specific queries.
    https://cran.r-project.org/web/packages/rsdmx/vignettes/quickstart.html

    Eurostat also provides links to SDMX converters.
    https://ec.europa.eu/eurostat/web/sdmx-infospace/sdmx-it-tools/sdmx-converter

    I have identified a brand new package to download and manipulate information from Eurostat.
    https://ropengov.github.io/eurostat/


```{r remeber, echo=F}
#Ctrl+Shift+Enter run the code
#Ctrl+Alt+I Create a new chunck
#Ctrl+Shift+K html preview of the notebook


#Also
#When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

#The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

```




